# Press-to-Speak Translation App

A real-time voice translation mobile application that allows users to speak in one language and instantly translate their speech to another language with voice output.

## ğŸ“± Overview

This project enables users to:
- Speak in their native language
- Get instant translation to their selected target language
- Hear the translated text in their preferred voice
- Manage their profile and subscription settings

## ğŸ—ï¸ Project Structure

```
press-to-speak/
â”œâ”€â”€ client/          # React Native mobile app (Android/iOS)
â”œâ”€â”€ server/          # Node.js & Express REST API
â””â”€â”€ README.md
```

### Components
- **Client**: React Native mobile application for Android and iOS
- **Server**: Node.js and Express-based REST API
- **Database**: MongoDB for user registration and translation data storage

## âœ¨ Features

### Core Functionality
- **Speech Recognition**: Convert user's voice to text using Google or ChatGPT APIs
- **Text Translation**: Real-time translation to selected language using ChatGPT or Google Translate API
- **Text-to-Speech**: Play translated text with voice output similar to user's voice
- **User Management**: Registration, login, and subscription management
- **Language Selection**: Support for multiple languages
- **Audio Visualization**: Real-time audio spectrum display

### User Interface
- **Speak Screen**: Main interface for voice input and translation
- **Profile Screen**: User account and settings management
- **Language Selector**: Choose source and target languages
- **Speech Button**: Press-to-speak functionality with visual feedback

## ğŸ› ï¸ Technologies

### Frontend (Client)
- **React Native** - Cross-platform mobile development
- **JavaScript** - Programming language
- **React Native Audio** - Audio recording and playback
- **React Native Speech** - Speech recognition

### Backend (Server)
- **Node.js** - Runtime environment
- **Express.js** - Web framework
- **MongoDB** - Database
- **JWT** - Authentication
- **Bcrypt** - Password hashing

### APIs & Services
- **Google Speech-to-Text API** - Voice recognition
- **Google Translate API** - Text translation
- **Google Text-to-Speech API** - Voice synthesis
- **ChatGPT API** - Alternative translation service

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** (v14 or higher) and npm
- **MongoDB** (Local installation or MongoDB Atlas)
- **Android Studio** (for Android development)
- **Xcode** (for iOS development, macOS only)
- **React Native CLI** (`npm install -g react-native-cli`)

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/CotNeo/press-to-speak.git
cd press-to-speak
```

### 2. Server Setup

Navigate to the server directory:

```bash
cd server
```

Install dependencies:

```bash
npm install
```

Create environment variables file:

Create a `.env` file in the server directory with the following variables:

```env
MONGO_URI=your_mongodb_connection_string
JWT_SECRET=your_jwt_secret_key
PORT=5000
GOOGLE_API_KEY=your_google_api_key
OPENAI_API_KEY=your_openai_api_key
```

Start the server:

```bash
npm run dev
```

The server will run on `http://localhost:5000`

### 3. Client Setup

Navigate to the client directory:

```bash
cd client
```

Install dependencies:

```bash
npm install
```

For iOS, install CocoaPods dependencies:

```bash
cd ios && pod install && cd ..
```

Create environment variables file:

Create a `.env` file in the client directory:

```env
API_URL=http://localhost:5000/api
```

### 4. Database Setup

Make sure MongoDB is running locally or use MongoDB Atlas:

- **Local MongoDB**: Ensure MongoDB service is running
- **MongoDB Atlas**: Use the connection string in your `.env` file

## ğŸƒâ€â™‚ï¸ Running the Application

### Android

```bash
# Start Metro bundler
npx react-native start

# Run on Android (in a new terminal)
npx react-native run-android
```

### iOS (macOS only)

```bash
# Start Metro bundler
npx react-native start

# Run on iOS (in a new terminal)
npx react-native run-ios
```

## ğŸ“± Usage

1. **Launch the app** on your device or emulator
2. **Register or login** to access the application
3. **Select languages** using the language selector
4. **Press and hold** the speech button to start recording
5. **Speak your message** in the source language
6. **Release the button** to stop recording
7. **View the translation** on screen and listen to the audio output

## ğŸ”§ Configuration

### API Keys Setup

1. **Google APIs**:
   - Enable Speech-to-Text API
   - Enable Translate API
   - Enable Text-to-Speech API
   - Get API key from Google Cloud Console

2. **OpenAI API** (Optional):
   - Get API key from OpenAI platform
   - Add to server `.env` file

### Environment Variables

#### Server (.env)
```env
MONGO_URI=mongodb://localhost:27017/press-to-speak
JWT_SECRET=your-super-secret-jwt-key
PORT=5000
GOOGLE_API_KEY=your-google-api-key
OPENAI_API_KEY=your-openai-api-key
```

#### Client (.env)
```env
API_URL=http://localhost:5000/api
```

## ğŸ§ª Testing

Run tests for the server:

```bash
cd server
npm test
```

## ğŸ“ Project Structure Details

### Server Structure
```
server/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ db.js              # Database configuration
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ authController.js   # Authentication logic
â”‚   â”œâ”€â”€ speechController.js # Speech processing
â”‚   â””â”€â”€ userController.js   # User management
â”œâ”€â”€ middlewares/
â”‚   â”œâ”€â”€ authMiddleware.js   # JWT authentication
â”‚   â””â”€â”€ errorHandler.js     # Error handling
â”œâ”€â”€ models/
â”‚   â””â”€â”€ User.js            # User data model
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ authRoutes.js      # Authentication routes
â”‚   â”œâ”€â”€ speechRoutes.js    # Speech processing routes
â”‚   â””â”€â”€ userRoutes.js      # User management routes
â”œâ”€â”€ services/
â”‚   â””â”€â”€ speechService.js   # Speech processing service
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ validators.js      # Input validation
â””â”€â”€ index.js               # Server entry point
```

### Client Structure
```
client/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ AudioSpectrum.js    # Audio visualization
â”‚   â”œâ”€â”€ LanguageSelector.js # Language selection
â”‚   â””â”€â”€ SpeechButton.js     # Speech input button
â”œâ”€â”€ screens/
â”‚   â”œâ”€â”€ ProfileScreen.js    # User profile
â”‚   â””â”€â”€ SpeakScreen.js      # Main translation screen
â”œâ”€â”€ services/
â”‚   â””â”€â”€ api.js             # API communication
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ commonStyles.js    # Shared styles
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.js         # Utility functions
â””â”€â”€ App.js                 # Main app component
```

## ğŸ› Troubleshooting

### Common Issues

1. **Metro bundler issues**:
   ```bash
   npx react-native start --reset-cache
   ```

2. **Android build issues**:
   ```bash
   cd android && ./gradlew clean && cd ..
   npx react-native run-android
   ```

3. **iOS build issues**:
   ```bash
   cd ios && pod install && cd ..
   npx react-native run-ios
   ```

4. **Database connection issues**:
   - Check MongoDB is running
   - Verify connection string in `.env`
   - Check network connectivity

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the troubleshooting section
2. Search existing issues
3. Create a new issue with detailed description
4. Include logs and error messages

## ğŸ”® Future Enhancements

- [ ] Offline translation support
- [ ] More language options
- [ ] Voice customization
- [ ] Translation history
- [ ] Export functionality
- [ ] Multi-user support
- [ ] Real-time collaboration

